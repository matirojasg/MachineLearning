{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"InformeTarea1.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"oarokQbeHish","colab_type":"text"},"source":["<center><h1>Informe Tarea 1.</h1>  \n","Tema:  Análisis de sentimientos en Tweets\n","  \n","Integrantes: Matías Rojas y María José Trujillo. </center>\n","\n"]},{"cell_type":"markdown","metadata":{"id":"oJ7wJbbBI_wj","colab_type":"text"},"source":["<h2><b> Introducción. </b></h2>\n","\n","\n","El análisis de sentimientos en tweets pertenece a un área de investigación del procesamiento de lenguaje natural, con aplicaciones en cuanto al tratamiento   computacional   de   opiniones, sentimientos  y subjetividad  en  textos. Esta área  tiene diversas sub-áreas tales como la clasificación de textos binaria en negativos o positivos, en un rango de positividad o negatividad, entre otras. En esta tarea en particular, se analizará la intensidad de sentimientos en diversos textos que fueron obtenidos desde twitter, en específico se analizarán textos que representan sentimientos de enojo, alegría, miedo y tristeza, y se crearan modelos para clasificar en tres clases: bajo, medio y alto, que representan la intensidad del texto.\n","\n","Formalmente, la task recibe como input un texto $w$, y devuelve como output una clase $c_{i}$ $\\in$ {low,medium,high} y las métricas a utilizar para medir que tan acertado es el modelo serán auc, kappa y average.\n","\n","Para poder entrenar el modelo se utilizará el procedimiento estandar al momento de entrenar modelos utilizando machine learning, es decir, tres conjuntos: training, validación y testing. El conjunto de training y validación es entregado por el cuerpo docente, son 4 conjuntos donde cada uno está asociado a cada sentimiento. Cada uno de estos conjuntos se  divide en un $66.6\\%$ para entrenar y luego un $33.3\\%$ para la validación. Finalmente, el conjunto de testing es un conjunto gold que será utilizado para medir la generalización del modelo y con esto se obtendrá el puntaje de la competencia.\n","\n","En cuanto a los modelos, el enfoque de la tarea o más bien desafío será analizar que tan alta puede ser la efectividad de la predicción utilizando herramientas vistas hasta el momento en el curso, es decir, clasificadores. Para ello, se partirá con el baseline entregado por el cuerpo docente: \n","<a href=\"https://github.com/dccuchile/CC6205/tree/master/assignments/assignment_1\">Github,</a> y se probará con distintos clasificadores tales como SVM, NB, RandomForestClassifier, LogisticRegression, entre otros. Y distintas formas de vectorizar, tokenizando con herramientas como TweetTokenizer, utilización de n-gramas de palabras y caractéres, utilización de lexicons, entre otros. Finalmente, se realizará un cuadro comparativo de todos los métodos.\n"]},{"cell_type":"markdown","metadata":{"id":"DoSgCJqhT8l8","colab_type":"text"},"source":["<h2><b>Trabajo relacionado.</h2></b>"]},{"cell_type":"markdown","metadata":{"id":"RifiVetTWFOP","colab_type":"text"},"source":["Para poder analizar el estado del arte en esta área hay que recalcar que no se está estudiando la clasificación de un texto en positivo o negativo, ya que en esa área hay muchas técnicas ya conocidas que se comportan bien en cuanto a métricas. En este caso lo que se está haciendo es medir la intensidad que tiene un sentimiento en particular, lo que supone un gran desafío debido a que no hay mucho estudio en estos casos. \n","\n","En el <a href=\"https://github.com/dccuchile/CC6205/tree/master/assignments/assignment_1\">paper</a> Emotion Intensities in Tweets escrito por Felipe Bravo y Saif M. Mohammad, se mencionan trabajos realizados en el área: \n","\n","Strapparava and Mihalcea (2007): Lo que se hizo fue que diferentes personas pudieran clasificar la intensidad de una noticia en una escala de 1 a 100 mediante una barras deslizantes mostradas en una interfaz web. El problema de este experimento es el sesgo que aparece al momento de comparar los puntajes asignados por distintas personas, debido a que para algunas personas la emoción en el texto puede ser muy intensa pero para otras no tanto. Y como tienen 100 alternativas de puntuación es muy difícil que coincidan en un rango pequeño y esto puede ocasionar error en el entrenamiento de los modelos, problemas de generalización, entre otros.\n","\n","Kiritchenko y Mohammad (2017): Best-Worst Scaling es una tecnica desarrollada por Louviere en 1991 basada en investigaciones hechas en psicología matemática y psicofísica en 1960 por AnthonyA. J. Marley y Duncan Luce. \n","\n","Lo que se demostró a través de diversos experimentos es que  con BWS se abordan los desafíos de la puntuación directa y se producen puntajes de intensidad emocional más confiables en comparación a la asignación mediante barras deslizantes. Además, este será el primer conjunto de datos con puntajes emocionales para tweets.\n","\n","De todas formas, se menciona que aún queda mucho por investigar e implementar en esta área."]},{"cell_type":"markdown","metadata":{"id":"pcKw_s0sUIT-","colab_type":"text"},"source":["<h2><b>Algoritmos y representaciones.</h2></b>\n","\n","La idea será utilizar un código base donde lo único que irá variando a lo largo de los experimentos será el trozo de código con la función getclassifier(). La metodología para poder facilitar la revisión y reutilizar código será poner distintos trozos de códigos, cada uno asociado a un experimento en particular, luego el miembro del cuerpo docente puede ir variando los métodos. En general lo que se buscará antes de hacer algún submission será superar el promedio obtenido de las métricas en el baseline, pero haciendo un énfases en kappa para que el modelo no se comporte como aleatorio.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ihKSIxqtUVNE","colab_type":"text"},"source":["<h2><b>Experimentos</h2></b>"]},{"cell_type":"markdown","metadata":{"id":"J7RnQWL_Vfe9","colab_type":"text"},"source":["##Imports"]},{"cell_type":"code","metadata":{"id":"jHIraUsjRbuY","colab_type":"code","outputId":"5702685c-c935-46a5-befd-4556f6b5b6c8","executionInfo":{"status":"ok","timestamp":1569805272823,"user_tz":180,"elapsed":1869,"user":{"displayName":"Matias Rojas","photoUrl":"","userId":"06611082509338078725"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["# Imports necesarios para probar distintos clasificadores y tokenizaciones.\n","\n","import pandas as pd\n","import shutil\n","import string\n","import re\n","import nltk\n","import os\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.pipeline import Pipeline\n","from sklearn.metrics import confusion_matrix, cohen_kappa_score, classification_report, accuracy_score, roc_auc_score\n","from sklearn.model_selection import train_test_split\n","from nltk.tokenize import TweetTokenizer\n","from sklearn.linear_model import LogisticRegression\n","from nltk.sentiment.util import  mark_negation\n","from sklearn import svm\n","from nltk.tokenize import RegexpTokenizer\n","from sklearn.feature_extraction.text import TfidfTransformer\n","from nltk.stem.porter import PorterStemmer\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import f1_score, recall_score, precision_score\n","from sklearn.datasets import load_breast_cancer\n","from sklearn.dummy import DummyClassifier\n","from sklearn.svm import SVC  # support vector machine classifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.naive_bayes import GaussianNB  # naive bayes\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import classification_report\n","from sklearn.multiclass import OneVsRestClassifier\n","from sklearn.svm import LinearSVC\n","from nltk.corpus import opinion_lexicon  \n","from sklearn.pipeline import FeatureUnion\n","from sklearn.base import BaseEstimator, TransformerMixin\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import cross_validate\n","from sklearn.svm import LinearSVC\n","from sklearn.model_selection import GridSearchCV\n","from nltk.stem.porter import PorterStemmer\n","import numpy as np \n","porter_stemmer = PorterStemmer()\n","\n","\n","nltk.download('opinion_lexicon')\n","\n","# Descarga del dataset \n","\n","train = {\n","    'anger': pd.read_csv('https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/assignment_1/data/train/anger-train.txt', sep='\\t', names=['id', 'tweet', 'class', 'sentiment_intensity']),\n","    'fear': pd.read_csv('https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/assignment_1/data/train/fear-train.txt', sep='\\t', names=['id', 'tweet', 'class', 'sentiment_intensity']),\n","    'joy': pd.read_csv('https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/assignment_1/data/train/joy-train.txt', sep='\\t', names=['id', 'tweet', 'class', 'sentiment_intensity']),\n","    'sadness': pd.read_csv('https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/assignment_1/data/train/sadness-train.txt', sep='\\t', names=['id', 'tweet', 'class', 'sentiment_intensity'])\n","}\n","\n","target = {\n","    'anger': pd.read_csv('https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/assignment_1/data/target/anger-target.txt', sep='\\t', names=['id', 'tweet', 'class', 'sentiment_intensity'], na_values=['NONE']),\n","    'fear': pd.read_csv('https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/assignment_1/data/target/fear-target.txt', sep='\\t', names=['id', 'tweet', 'class', 'sentiment_intensity'], na_values=['NONE']),\n","    'joy': pd.read_csv('https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/assignment_1/data/target/joy-target.txt', sep='\\t', names=['id', 'tweet', 'class', 'sentiment_intensity'], na_values=['NONE']),\n","    'sadness': pd.read_csv('https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/assignment_1/data/target/sadness-target.txt', sep='\\t', names=['id', 'tweet', 'class', 'sentiment_intensity'], na_values=['NONE'])\n","}\n"],"execution_count":95,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package opinion_lexicon to /root/nltk_data...\n","[nltk_data]   Package opinion_lexicon is already up-to-date!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NnnM7b0XP7P6","colab_type":"text"},"source":["## Preprocesamiento:\n","Se ajusta el dataset para dejar todas las intensidades de sentimiento en la misma proporcion, es decir, se corta la clase medium para que tenga el mismo tamaño que high y low. De esta forma, no se sobresatura el clasificador con datos medium, evitando que sea más propenso a elegir esta intensidad.\n"]},{"cell_type":"code","metadata":{"id":"9bWv6ibWP3xV","colab_type":"code","outputId":"bfe4805b-08bc-40a8-9086-eaa75a650d72","executionInfo":{"status":"ok","timestamp":1569805272829,"user_tz":180,"elapsed":1862,"user":{"displayName":"Matias Rojas","photoUrl":"","userId":"06611082509338078725"}},"colab":{"base_uri":"https://localhost:8080/","height":463}},"source":["def get_group_dist(group_name, train):\n","    print(group_name, \"\\n\",\n","          train[group_name].groupby('sentiment_intensity').count())\n","from collections import Counter\n","from sklearn.utils import shuffle\n","nuevotrain= {}\n","import math\n","def subsampling(train):\n","\n","  for key in train:\n","    a=Counter(train[key].sentiment_intensity)['low']\n","    b=Counter(train[key].sentiment_intensity)['high']\n","    promedio= math.floor((a+b)/2)\n","    medium= shuffle(train[key][train[key].sentiment_intensity == 'medium'][1:])[0:promedio].copy()\n","    high= train[key][train[key].sentiment_intensity == 'high'].copy()\n","    low= train[key][train[key].sentiment_intensity == 'low'].copy()\n","    data=low.append(high).copy()\n","    data1=data.append(medium)\n","    nuevotrain[key]=data1.copy()\n"," \n","subsampling(train)\n","\n","for key in nuevotrain:\n","  get_group_dist(key, nuevotrain)\n"],"execution_count":96,"outputs":[{"output_type":"stream","text":["anger \n","                       id  tweet  class\n","sentiment_intensity                   \n","high                 163    163    163\n","low                  161    161    161\n","medium               162    162    162\n","fear \n","                       id  tweet  class\n","sentiment_intensity                   \n","high                 270    270    270\n","low                  288    288    288\n","medium               279    279    279\n","joy \n","                       id  tweet  class\n","sentiment_intensity                   \n","high                 195    195    195\n","low                  219    219    219\n","medium               207    207    207\n","sadness \n","                       id  tweet  class\n","sentiment_intensity                   \n","high                 197    197    197\n","low                  210    210    210\n","medium               203    203    203\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bldpBobCQcdL","colab_type":"text"},"source":["## Metricas y Split\n"]},{"cell_type":"code","metadata":{"id":"OA0zWo8wQgiB","colab_type":"code","colab":{}},"source":["# Definición de la métrica de evaluación auc\n","\n","def auc(test_set, predicted_set):\n","    high_predicted = np.array([prediction[2] for prediction in predicted_set])\n","    medium_predicted = np.array(\n","        [prediction[1] for prediction in predicted_set])\n","    low_predicted = np.array([prediction[0] for prediction in predicted_set])\n","\n","    high_test = np.where(test_set == 'high', 1.0, 0.0)\n","    medium_test = np.where(test_set == 'medium', 1.0, 0.0)\n","    low_test = np.where(test_set == 'low', 1.0, 0.0)\n","\n","    auc_high = roc_auc_score(high_test, high_predicted)\n","    auc_med = roc_auc_score(medium_test, medium_predicted)\n","    auc_low = roc_auc_score(low_test, low_predicted)\n","\n","    auc_w = (low_test.sum() * auc_low + medium_test.sum() * auc_med +\n","             high_test.sum() * auc_high) / (\n","                 low_test.sum() + medium_test.sum() + high_test.sum())\n","    return auc_w \n","\n","def split_dataset(dataset):\n","    # Dividir el dataset en train set y test set\n","    X_train, X_test, y_train, y_test = train_test_split(\n","        dataset.tweet,\n","        dataset.sentiment_intensity,\n","        shuffle=True,\n","        test_size=0.3)\n","    return X_train, X_test, y_train, y_test"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CYuuLKnkQtsr","colab_type":"text"},"source":["##Tipos de experimentos realizados\n"]},{"cell_type":"markdown","metadata":{"id":"NcZFeLscOQBe","colab_type":"text"},"source":["###Experimento 0:\n","Baseline equipo docente"]},{"cell_type":"code","metadata":{"id":"vgrWglA3DYyV","colab_type":"code","colab":{}},"source":["def experimento_0():\n","    vectorizer = CountVectorizer()\n","    naive_bayes = MultinomialNB()\n","    text_clf = Pipeline([('vect', vectorizer), ('clf', naive_bayes)])\n","    return text_clf\n","    \n","    \n","    "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bhIaiJm7OhRi","colab_type":"text"},"source":["###Experimento 1:\n","Consiste en mantener el clasificador utilizado (NaiveBayes) en el baseline pero variando el vectorizador. Para ello se realizaron diversas pruebas obteniendo como mejor configuración la utilización de TweetTokenizer, mark_negation y un análisis de n-gramas de palabras.\n","Se utiliza ngram_range(1,4) como se especifica en el paper \"Emotion Intensities in Tweets\" por Saif M. Mohammad y Felipe Bravo-Marquez\n","\n","\n","Se utiliza CountVectorizer como vectorizador y LogisticRegression. Se le agregan distintos paramétros para optimizar la classificación. A grandes rasgos estos son: \n","\n","TweetTokenizer: Tokenizador especial para tweets, clasifica emojis, borra las menciones (strip_handles) y hace downcase (preserve_case=False) \n","\n","CountVectorizer: Es el vectorizador que pasa el texto a BOW, también recibe varios parámetros que optimizan este cambio. Analyzer es como se tokenizaran los textos, por ejemplo, si este parámetro se encuentra en como 'word', se tokenizan palabras. Si es tipo 'char' se tokenizan caracteres. Char_wb es como char, pero no pasa los límites de las palabras. \n","Luego se probar distintos analyzers, word mostró mejor desempeño. (Experimentos omitidos por su similitud al experimento 1)\n","\n","Además, se añade como preprocesador mark_negation, el cual se encarga de darle intencionalidad a palabras neutrales según su contexto (por ejemplo algo positivo como like puede estar en el contexto didn't like y en la bag of words se pierda esta intencionalidad. Entonces, mark_negation lo cambia por like_NEG. Además, se puede ajustar el tamaño de los n-gramas y quitar las stop_words. \n","  ."]},{"cell_type":"code","metadata":{"id":"k6D8aQvNDZFN","colab_type":"code","colab":{}},"source":["def experimento_1():\n","    print(\"Experimento 1\")\n","    TOKENIZER = TweetTokenizer(strip_handles=True)\n","    vectorizer = CountVectorizer(analyzer='word', preprocessor= mark_negation ,tokenizer= TOKENIZER.tokenize,  ngram_range=(1,4), stop_words='english')\n","    clf = MultinomialNB()\n","    text_clf = Pipeline([('vect', vectorizer),('clf',clf)])\n","    return text_clf"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RJvB1-GscONL","colab_type":"text"},"source":["###Experimento 2:\n","Support Vector Machine:\n","Se cambia el clasificador por SVC, utilizando un kernel lineal, admitiendo probabilidades.\n"]},{"cell_type":"code","metadata":{"id":"JeieS0BccTVm","colab_type":"code","colab":{}},"source":["def experimento_2(): \n","    print(\"Experimento 2\")\n","    # Definimos el vectorizador para convertir el texto a BoW:\n","    TOKENIZER = TweetTokenizer(strip_handles=True, preserve_case=True )\n","    vectorizer = CountVectorizer(analyzer='word', preprocessor= mark_negation ,tokenizer= TOKENIZER.tokenize,  ngram_range=(1,4), stop_words='english')  \n","\n","    # Inicializamos el Clasificador.\n","    clf = svm.SVC(kernel='linear', probability= True, C=100, gamma='scale')\n","    # Establecer el pipeline.\n","    text_clf = Pipeline([('vect', vectorizer), ('clf', clf)])\n","    return text_clf"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r8_0J9G2Oz9R","colab_type":"text"},"source":["### Experimento 3:\n","Preprocesador de elaboracion propia.\n","Se probó con classificador NaiveBayes y Logistic regression. Se dejó NaiveBayes por consistencia con los otros experimentos ya que logisticRegression será explicado el en experimento 4 en más detalle. La idea es eliminar las palabras que correspondan a expresiones regulares y que a priori no otorguen información extra al modelo. Como también la aplicación de un stemming para probar las herramientas vistas en el curso.\n","\n","Como no funcionó, se volvió a mark_negation para los siguientes experimentos.\n"]},{"cell_type":"code","metadata":{"id":"vksX0TxwDZaD","colab_type":"code","colab":{}},"source":["def experimento_3():\n","    print(\"Experimento 3\")\n","    def my_preprocessor(doc):\n","       preprocessed_doc = re.sub(r'[^\\w\\s+]', '', str(doc)).lower() \n","       doc2 = mark_negation(preprocessed_doc)\n","       doc3 = porter_stemmer.stem(doc2)\n","       return doc3\n"," \n","    tokenizertweet = TweetTokenizer(strip_handles=True)\n","    vectorizer = CountVectorizer(analyzer='word', preprocessor = my_preprocessor, tokenizer = tokenizertweet.tokenize, ngram_range=(1,4), stop_words='english')\n","    clf =  MultinomialNB()\n","    text_clf = Pipeline([('vect', vectorizer),('clf',clf)])\n","    return text_clf"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iM0CF1SPO-SL","colab_type":"text"},"source":["###Experimento 4:\n","Se cambia NaiveBayes por LogisticRegression, con sus parametros por defecto (solver y multi_class, que se escribieron por fines visuales). Además, se aumentó el número de iteraciones a 1000, pues con su valor por defecto (iter=100) no alcanzaba a converger (y por ende mostraba un warning)"]},{"cell_type":"code","metadata":{"id":"OZCjP08CDZmH","colab_type":"code","colab":{}},"source":["def experimento_4():\n","    print(\"Experimento 4\")\n","    # Experimento 4: Logistic regression using word n-grams\n","    tokenizertweet = TweetTokenizer(strip_handles=True)\n","    vectorizer = CountVectorizer(analyzer=\"char_wb\",tokenizer = tokenizertweet.tokenize, preprocessor = mark_negation, ngram_range=(1,10), stop_words=\"english\")  \n","    log_mod = LogisticRegression(solver='liblinear',multi_class='ovr', iter=1000)   \n","    text_clf = Pipeline([('vect', vectorizer), ('clf', log_mod)])\n","    return text_clf\n","    \n","    "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"41RJ_QzgPRSH","colab_type":"text"},"source":["###Experimento 5:\n","En el cuarto experimento, se utilizó la recomendación del cuerpo docente de fijarnos más en la ingeniería de features que en los clasificadores o n-grammas, para ello se decidió usar lexicones desde los <a href=\"https://affectivetweets.cms.waikato.ac.nz/benchmark/\">benchmarks</a> recomendados en el auxiliar 1 y probar su rendimiento. La idea es a partir de datos etiquetados como palabras positivas y negativas desde el conjunto opinion_lexicon, analizar en los tweets cuántas de estas palabras aparecen en los tweets para poder caracterizarlos y después analizar bajo el mismo procedimiento del PipeLine, TweetTokenizator y LogisticRegression el rendimiento del modelo."]},{"cell_type":"code","metadata":{"id":"eHlRqCA1EVxG","colab_type":"code","colab":{}},"source":["\n","\n","class LiuFeatureExtractor(BaseEstimator, TransformerMixin):\n","\n","    def __init__(self, tokenizer):\n","        self.tokenizer = tokenizer\n","        self.pos_set = set(opinion_lexicon.positive())\n","        self.neg_set = set(opinion_lexicon.negative())\n","\n","    def liu_score(self,sentence): \n","        tokenized_sent = self.tokenizer.tokenize(sentence)\n","        pos_words = 0\n","        neg_words = 0\n","        for word in tokenized_sent:\n","            if word in self.pos_set:\n","                pos_words += 1\n","            elif word in self.neg_set:\n","                neg_words += 1\n","        return [pos_words,neg_words]\n","\n","    def transform(self, X, y=None):\n","        values = []\n","        for tweet in X:\n","            values.append(self.liu_score(tweet))\n","\n","        return(np.array(values))\n","\n","    def fit(self, X, y=None):\n","        return self\n","\n","def experimento_5():\n","    print(\"Experimento 5\")\n","    tokenizer = TweetTokenizer(preserve_case=False, reduce_len=True)\n","    liu_feat = LiuFeatureExtractor(tokenizer)\n","    vectorizer = CountVectorizer(analyzer='char',tokenizer = tokenizer.tokenize, lowercase=False, preprocessor = mark_negation, ngram_range=(3,5))  \n","    log_mod = LogisticRegression(solver='liblinear',multi_class='ovr')   \n","    liu_ngram_clf = Pipeline([ ('feats', \n","                            FeatureUnion([ ('ngram', vectorizer), ('liu',liu_feat) ])),\n","    ('clf', log_mod)])\n","\n","    return liu_ngram_clf        \n","      "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MxT7vayFRvvF","colab_type":"text"},"source":["##Resto del código\n","Se elige el experimento en la funcion get_classifier\n"]},{"cell_type":"code","metadata":{"id":"Wn0fuMffLm-g","colab_type":"code","outputId":"66a7c99e-f3ce-4496-b3f4-91df9922c906","executionInfo":{"status":"ok","timestamp":1569805276009,"user_tz":180,"elapsed":4989,"user":{"displayName":"Matias Rojas","photoUrl":"","userId":"06611082509338078725"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["def get_classifier():\n","  # Se puede elegir cualquiera de los 5, basta con variar el método.\n","  return experimento_5()\n","\n","results ={}\n","def evaulate(predicted, y_test, labels):\n","    # Importante: al transformar los arreglos de probabilidad a clases,\n","    # entregar el arreglo de clases aprendido por el clasificador. \n","    # (que comunmente, es distinto a ['low', 'medium', 'high'])\n","    predicted_labels = [labels[np.argmax(item)] for item in predicted]\n","   \n","    # Confusion Matrix\n","    print('Confusion Matrix for {}:\\n'.format(key))\n","\n","    # Classification Report\n","    print(\n","        confusion_matrix(y_test,\n","                         predicted_labels,\n","                         labels=['low', 'medium', 'high']))\n","\n","    print('\\nClassification Report')\n","    print(\n","        classification_report(y_test,\n","                              predicted_labels,\n","                              labels=['low', 'medium', 'high']))\n","\n","    # AUC\n","    print(\"auc: \", auc(y_test, predicted))\n","\n","    # Kappa\n","    print(\"kappa:\", cohen_kappa_score(y_test, predicted_labels))\n","\n","    # Accuracy\n","    print(\"accuracy:\", accuracy_score(y_test, predicted_labels), \"\\n\")\n","\n","    print('------------------------------------------------------\\n\\n')\n","    results[key]={}\n","    results[key]['auc']=  auc(y_test, predicted)\n","    results[key]['kappa'] =cohen_kappa_score(y_test, predicted_labels)\n","    results[key]['accuracy']= accuracy_score(y_test, predicted_labels)\n","    \n","def classify(dataset, key):\n","\n","    X_train, X_test, y_train, y_test = split_dataset(dataset)\n","    text_clf = get_classifier()\n","    \n","    \n","    \n","    text_clf.fit(X_train, y_train)\n","    \n","    \n","    # Predecir las probabilidades de intensidad de cada elemento del set de prueba.\n","    predicted = text_clf.predict_proba(X_test)\n","    \n","    # Obtener las clases aprendidas.\n","    learned_labels = text_clf.classes_\n","\n","    # Evaluar\n","    evaulate(predicted, y_test, learned_labels)\n","    return text_clf, learned_labels\n","  \n","classifiers = []\n","learned_labels_array = []\n","\n","# Por cada llave en train ('anger', 'fear', 'joy', 'sadness')\n","for key in nuevotrain:\n","    classifier, learned_labels = classify(nuevotrain[key], key)\n","    classifiers.append(classifier)\n","    learned_labels_array.append(learned_labels)\n","\n","#print(results)\n","print('SUMA: ')\n","print('auc: ' + str(results['anger']['auc'] + results['fear']['auc'] +results['joy']['auc'] + results['sadness']['auc'] ))  \n","print('kappa: '+ str(results['anger']['kappa'] + results['fear']['kappa'] +results['joy']['kappa'] + results['sadness']['kappa'] )) \n","print('accuracy: '+ str(results['anger']['accuracy'] + results['fear']['accuracy'] +results['joy']['accuracy'] + results['sadness']['accuracy'] ))       \n","    \n","def predict_target(dataset, classifier, labels):\n","    # Predecir las probabilidades de intensidad de cada elemento del target set.\n","    predicted = pd.DataFrame(classifier.predict_proba(dataset.tweet), columns=labels)\n","    # Agregar ids\n","    predicted['id'] = dataset.id.values\n","    # Reordenar\n","    predicted = predicted[['id', 'low', 'medium', 'high']]\n","    return predicted\n","predicted_target = {}\n","\n","if (not os.path.isdir('./predictions')):\n","    os.mkdir('./predictions')\n","\n","else:\n","    # Eliminar predicciones anteriores:\n","    shutil.rmtree('./predictions')\n","    os.mkdir('./predictions')\n","\n","for idx, key in enumerate(target):\n","    # Predecir el target set\n","    predicted_target[key] = predict_target(target[key], classifiers[idx],\n","                                           learned_labels_array[idx])\n","    # Guardar predicciones\n","    predicted_target[key].to_csv('./predictions/{}-pred.txt'.format(key),\n","                                 sep='\\t',\n","                                 header=False,\n","                                 index=False)\n","\n","# Crear archivo zip\n","a = shutil.make_archive('predictions', 'zip', './predictions')"],"execution_count":104,"outputs":[{"output_type":"stream","text":["Experimento 5\n","Confusion Matrix for anger:\n","\n","[[21 28 11]\n"," [12 20 12]\n"," [ 4 13 25]]\n","\n","Classification Report\n","              precision    recall  f1-score   support\n","\n","         low       0.57      0.35      0.43        60\n","      medium       0.33      0.45      0.38        44\n","        high       0.52      0.60      0.56        42\n","\n","    accuracy                           0.45       146\n","   macro avg       0.47      0.47      0.46       146\n","weighted avg       0.48      0.45      0.45       146\n","\n","auc:  0.4157364148884491\n","kappa: 0.18866351764378975\n","accuracy: 0.4520547945205479 \n","\n","------------------------------------------------------\n","\n","\n","Experimento 5\n","Confusion Matrix for fear:\n","\n","[[49 26  2]\n"," [21 44 29]\n"," [ 9 20 52]]\n","\n","Classification Report\n","              precision    recall  f1-score   support\n","\n","         low       0.62      0.64      0.63        77\n","      medium       0.49      0.47      0.48        94\n","        high       0.63      0.64      0.63        81\n","\n","    accuracy                           0.58       252\n","   macro avg       0.58      0.58      0.58       252\n","weighted avg       0.57      0.58      0.57       252\n","\n","auc:  0.32598682594907336\n","kappa: 0.36161750082863764\n","accuracy: 0.5753968253968254 \n","\n","------------------------------------------------------\n","\n","\n","Experimento 5\n","Confusion Matrix for joy:\n","\n","[[43 15  3]\n"," [24 22 17]\n"," [ 7 10 46]]\n","\n","Classification Report\n","              precision    recall  f1-score   support\n","\n","         low       0.58      0.70      0.64        61\n","      medium       0.47      0.35      0.40        63\n","        high       0.70      0.73      0.71        63\n","\n","    accuracy                           0.59       187\n","   macro avg       0.58      0.59      0.58       187\n","weighted avg       0.58      0.59      0.58       187\n","\n","auc:  0.34919539663372684\n","kappa: 0.3909838875557079\n","accuracy: 0.5935828877005348 \n","\n","------------------------------------------------------\n","\n","\n","Experimento 5\n","Confusion Matrix for sadness:\n","\n","[[34 16  4]\n"," [17 30 22]\n"," [12 15 33]]\n","\n","Classification Report\n","              precision    recall  f1-score   support\n","\n","         low       0.54      0.63      0.58        54\n","      medium       0.49      0.43      0.46        69\n","        high       0.56      0.55      0.55        60\n","\n","    accuracy                           0.53       183\n","   macro avg       0.53      0.54      0.53       183\n","weighted avg       0.53      0.53      0.53       183\n","\n","auc:  0.3721940300447209\n","kappa: 0.29546065001343\n","accuracy: 0.5300546448087432 \n","\n","------------------------------------------------------\n","\n","\n","SUMA: \n","auc: 1.4631126675159702\n","kappa: 1.2367255560415653\n","accuracy: 2.151089152426651\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mUL7b-fjbcuX","colab_type":"text"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"XVEi0kb8VsTC","colab_type":"text"},"source":["## Comparación métricas  \n","\n","Para poder comparar los modelos utilizados para los mejores 5 experimentos hechos se realiza un cuadro comparativo donde se muestran los valores de las tres métricas en ellos. \n","<hr>\n","<table class=\"egt\">\n","  <tr>\n","    <td>Métricas</td>\n","    <td>Baseline</td>\n","    <td>Experimento 1</td>\n","    <td>Experimento 2</td>\n","    <td>Experimento 3</td>\n","    <td>Experimento 4</td>\n","    <td>Experimento 5</td>\n","  </tr>\n","  <tr>\n","    <td>auc_angry</td>\n","    <td>0.44 </td>\n","    <td>0.41</td>\n","    <td>0.40</td>\n","    <td>0.40</td>\n","    <td>0.45</td>\n","    <td>0.44</td>\n","  </tr>\n","  <tr>\n","    <td>kappa_angry</td>\n","    <td>0.21 </td>\n","    <td>0.22</td>\n","    <td>0.23</td>\n","    <td>0.23</td>\n","    <td>0.31</td>\n","    <td>0.29</td>\n","  </tr>\n","  <tr>\n","    <td>accuracy_angry</td>\n","    <td>0.7</td>\n","    <td>0.48</td>\n","    <td>0.47</td>\n","    <td>0.49</td>\n","    <td>0.68</td>\n","    <td>0.53</td>\n","  </tr>\n","  \n","   <tr>\n","    <td>auc_fear</td>\n","    <td>0.44 </td>\n","    <td>0.41</td>\n","    <td>0.40</td>\n","    <td>0.36</td>\n","    <td>0.45</td>\n","    <td>0.38</td>\n","  </tr>\n","  <tr>\n","    <td>kappa_fear</td>\n","    <td>0.19</td>\n","    <td>0.30</td>\n","    <td>0.30</td>\n","    <td>0.37</td>\n","    <td>0.16</td>\n","    <td>0.32</td>\n","  </tr>\n","  <tr>\n","    <td>accuracy_fear</td>\n","    <td>0.58</td>\n","    <td>0.53</td>\n","    <td>0.53</td>\n","    <td>0.58</td>\n","    <td>0.53</td>\n","    <td>0.55</td>\n","  </tr>\n","  \n","   <tr>\n","    <td>auc_joy</td>\n","    <td>0.40</td>\n","    <td>0.37</td>\n","    <td>0.38</td>\n","    <td>0.38</td>\n","    <td>0.42</td>\n","    <td>0.34</td>\n","  </tr>\n","  <tr>\n","    <td>kappa_joy</td>\n","    <td>0.19</td>\n","    <td>0.36</td>\n","    <td>0.35</td>\n","    <td>0.20</td>\n","    <td>0.28</td>\n","    <td>0.32</td>\n","  </tr>\n","  <tr>\n","    <td>accuracy_joy</td>\n","    <td>0.55</td>\n","    <td>0.57</td>\n","    <td>0.57</td>\n","    <td>0.47</td>\n","    <td>0.6</td>\n","    <td>0.55</td>\n","  </tr>\n","  \n","   <tr>\n","    <td>auc_sadness</td>\n","    <td>0.45</td>\n","    <td>0.33</td>\n","    <td>0.43</td>\n","    <td>0.43</td>\n","    <td>0.44</td>\n","    <td>0.37</td>\n","  </tr>\n","  <tr>\n","    <td>kappa_sadness</td>\n","    <td>0.11</td>\n","    <td>0.33</td>\n","    <td>0.19</td>\n","    <td>0.36</td>\n","    <td>0.26</td>\n","    <td>0.38</td>\n","  </tr>\n","  <tr>\n","    <td>accuracy_sadness</td>\n","    <td>0.52</td>\n","    <td>0.55</td>\n","    <td>0.46</td>\n","    <td>0.57</td>\n","    <td>0.55</td>\n","    <td>0.58</td>\n","  </tr>\n","</table>\n","\n","Analizando esta tabla, se tomaron 4 de estos experimentos para realizar las submissions, donde las mejores dos corresponden las experimento 4 y 5 respectivamente, con los siguientes valores: \n","\n","<table class=\"egt\">\n","  <tr>\n","    <td>Métricas</td>\n","    <td>Baseline</td>\n","    <td>Experimento 4</td>\n","    <td>Experimento 5</td>\n","  </tr>\n","  <tr>\n","    <td>auc_avg</td>\n","    <td>0.64</td>\n","    <td>0.68</td>\n","    <td>0.68</td>\n","  </tr>\n","  <tr>\n","    <td>kappa_avg</td>\n","    <td>0.14</td>\n","    <td>0.25</td>\n","    <td>0.26</td>\n","  </tr>\n","  <tr>\n","    <td>accuracy_avg</td>\n","    <td>0.57</td>\n","    <td>0.58</td>\n","    <td>0.51</td>\n","  </tr>\n","</table>"]},{"cell_type":"markdown","metadata":{"id":"FALutmyLUZ7n","colab_type":"text"},"source":["##Conclusiones\n","\n","\n","Los resultados mostrados en las tablas fueron realizados se realizaron en base a los últimos experimentos ejecutados, obteniendo los mejores resultados pero cabe mencionar que también se realizaron otro tipo de experimentos como incorporar cross-validation, GridSearchCv, clasificadores como KNN, DecisionTree pero sin buenos resultados.\n","\n","Cabe destacar que la última optimización fue realizar un UnderSampling del dataset, para balancear las clases de intensidad de sentimientos. \n","Cuando se volvieron a correr los experimentos, todos subieron considerablemente su desempeño. Sin embargo, solo la ultima submition a la competencia contiene esta optimización y por ello, existe una gran diferencia de performance, priorizando la métrica kappa por sobre el accuracy.\n","\n","Al analizar la tabla con los valores obtenidos de las métricas, se puede apreciar que la mayoría de los experimentos superan el baseline entregado por el cuerpo docente.\n","\n","Se concluye que los experimentos 4 y 5 obtuvieron mejores resultados al momento de generalizar, superando al baseline en la métrica kappa.\n","\n","Se considera la metrica kappa la más confiable de las tres, dado que es la que define cuanto se aleja el modelo de los resultados aleatorios, por ende, cuando el modelo clasifica algo correctamente, no fue cuestión de azar. Por otro lado, se considera que la metrica menos apropiada (y que fue la peor del modelo) fue la del accuracy, pues al ser la clase medium mucho mayor a las otras, el modelo estará siempre máás inclinado a responder esto. Y como los datos de evualuación también tenian este desbalance, modelos con mayor accuracy podrían elegir medium por cuestión de azar y tener mejores resultados en dicha métrica.\n","\n","Además, se observa que la restricción del código a técnicas menos sofisticadas como las redes neuronales fue un limitante al momento de obtener mejores resultados en la competencia. \n","\n","Las dificultades principales de esta tarea surgen por el desconocimiento de qué features utilizar y en qué momento usar ciertos clasificadores, además de que las métricas utilizadas daban valores relativamente distintos al momento de generalizar el modelo con los datos gold de la competencia.\n","Este problema mencionado anteriormente puede deberse al desbalance que tienen las clases,como se mencionó anteriormente, generando errores de generalización. \n","Por otro lado, experimentando con las diversas técnicas vistas en el curso de Stemming, Lemmatization y Stopwords no mejoraron los resultados por lo que se podría concluir que al momento de analizar tweets es difícil evitar la eliminación de información relevante si se aplican estas técnicas. \n","\n","Finalmente, se concluye como mejor resultado el experimento 5, el cual consistía en utilizar LinearRegression, TweetTokenizer y mark_negation. Sin embargo, se considera como la pieza angular del preprocesamiento el balanceo del dataset de entrenamiento, ya que luego de su implementación este experimento y todos los otros aumentaron considerablemente su desempeño general. \n","Lamentablemente, existen otras técnicas no experimentadas como embeddings y redes neuronales, entre otras técnicas relacionadas. \n"]}]}